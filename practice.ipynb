{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensors of type SparseTensorImpl do not have strides",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/birch/git/t5-booru/practice.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 173>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/birch/git/t5-booru/practice.ipynb#ch0000000?line=169'>170</a>\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mforward(batch_of_captions_tensor)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/birch/git/t5-booru/practice.ipynb#ch0000000?line=171'>172</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model\u001b[39m=\u001b[39mmodel, batches\u001b[39m=\u001b[39mbatches, epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/birch/git/t5-booru/practice.ipynb#ch0000000?line=172'>173</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "\u001b[1;32m/Users/birch/git/t5-booru/practice.ipynb Cell 1'\u001b[0m in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/birch/git/t5-booru/practice.ipynb#ch0000000?line=167'>168</a>\u001b[0m \u001b[39mwhile\u001b[39;00m epoch \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/birch/git/t5-booru/practice.ipynb#ch0000000?line=168'>169</a>\u001b[0m   batch_of_captions_tensor: BoolTensor \u001b[39m=\u001b[39m captions_to_tensor(captions[:\u001b[39m2\u001b[39m])\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/birch/git/t5-booru/practice.ipynb#ch0000000?line=169'>170</a>\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mforward(batch_of_captions_tensor)\n",
      "\u001b[1;32m/Users/birch/git/t5-booru/practice.ipynb Cell 1'\u001b[0m in \u001b[0;36mMultilabelEmbedding.forward\u001b[0;34m(self, batch_of_captions_tensor)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/birch/git/t5-booru/practice.ipynb#ch0000000?line=51'>52</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch_of_captions_tensor: BoolTensor):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/birch/git/t5-booru/practice.ipynb#ch0000000?line=52'>53</a>\u001b[0m   embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(batch_of_captions_tensor)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/birch/git/t5-booru/practice.ipynb#ch0000000?line=53'>54</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/git/t5-booru/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1186\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1185\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1186\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1187\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/git/t5-booru/venv/lib/python3.9/site-packages/torch/nn/modules/sparse.py:159\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 159\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    160\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    161\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/git/t5-booru/venv/lib/python3.9/site-packages/torch/nn/functional.py:2197\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2191\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2192\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2193\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2194\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2195\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2197\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors of type SparseTensorImpl do not have strides"
     ]
    }
   ],
   "source": [
    "from torch.nn import Embedding, Module, CrossEntropyLoss\n",
    "\n",
    "from typing import Tuple, TypeVar, Iterable, Iterator, Callable\n",
    "from typing_extensions import TypeAlias\n",
    "from enum import Enum, auto\n",
    "from math import ceil\n",
    "from torch import BoolTensor, LongTensor, sparse_coo_tensor, ones\n",
    "from itertools import chain, islice, tee, count\n",
    "from torch import bfloat16\n",
    "\n",
    "class Label(Enum):\n",
    "  touhou = 0\n",
    "  hololive = auto()\n",
    "  marisa = auto()\n",
    "  reimu = auto()\n",
    "  youmu = auto()\n",
    "  sakuya = auto()\n",
    "  flandre = auto()\n",
    "  reiuji = auto()\n",
    "  reisen = auto()\n",
    "  tewi = auto()\n",
    "  patchouli = auto()\n",
    "  aya = auto()\n",
    "  pekora = auto()\n",
    "  kronii = auto()\n",
    "  gura = auto()\n",
    "  suisei = auto()\n",
    "  ame = auto()\n",
    "  noel = auto()\n",
    "  subaru = auto()\n",
    "  kiara = auto()\n",
    "  black_hair = auto()\n",
    "  silver_hair = auto()\n",
    "  blue_hair = auto()\n",
    "  blonde_hair = auto()\n",
    "  purple_hair = auto()\n",
    "  orange_hair = auto()\n",
    "  bunny_ears = auto()\n",
    "  bird_person = auto()\n",
    "\n",
    "vocab_size=len(Label)\n",
    "# t5-small compressed 32100 vocab tokens into 512 dims\n",
    "# there's plenty of range per bfloat16 to represent a variety of tokens\n",
    "embedding_dim=ceil(512/32100 * vocab_size)\n",
    "\n",
    "class MultilabelEmbedding(Module):\n",
    "  embedding: Embedding\n",
    "  def __init__(self, embedding: Embedding) -> None:\n",
    "    super(MultilabelEmbedding, self).__init__()\n",
    "    self.embedding = embedding\n",
    "  \n",
    "  def forward(self, batch_of_captions_tensor: BoolTensor):\n",
    "    embeddings = self.embedding(batch_of_captions_tensor)\n",
    "    return embeddings\n",
    "\n",
    "model = MultilabelEmbedding(\n",
    "  Embedding(\n",
    "    num_embeddings=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    sparse=True,\n",
    "    dtype=bfloat16\n",
    "  )\n",
    ")\n",
    "\n",
    "T = TypeVar('T')\n",
    "U = TypeVar('U')\n",
    "_Caption: TypeAlias = Tuple[Label, ...]\n",
    "_Captions: TypeAlias = Tuple[_Caption, ...]\n",
    "\n",
    "def make_row_indices(enumerated: Tuple[int, _Caption]) -> Tuple[int, ...]:\n",
    "  (ix, labels) = enumerated\n",
    "  return (ix,) * len(labels)\n",
    "\n",
    "def flatten(captions: Iterable[Tuple[T, ...]]) -> Iterable[T]:\n",
    "  return chain.from_iterable(captions)\n",
    "\n",
    "def get_value(label: Label) -> int:\n",
    "  return label.value\n",
    "\n",
    "def captions_to_tensor(captions: _Captions) -> BoolTensor:\n",
    "  row_indices: Tuple[int, ...] = tuple(flatten(map(make_row_indices, enumerate(captions))))\n",
    "  labels: Tuple[int, ...] = tuple(map(get_value, flatten(captions)))\n",
    "\n",
    "  indices_nominal: Tuple[Tuple[int, ...], Tuple[int, ...]] = (row_indices, labels)\n",
    "  return sparse_coo_tensor(\n",
    "    indices=LongTensor(indices_nominal),\n",
    "    values=ones(len(row_indices), dtype=bool),\n",
    "    dtype=bool)\n",
    "\n",
    "captions: _Captions = (\n",
    "  (Label.touhou, Label.marisa, Label.blonde_hair),\n",
    "  (Label.touhou, Label.reimu, Label.black_hair),\n",
    "  (Label.touhou, Label.youmu, Label.silver_hair),\n",
    "  (Label.touhou, Label.sakuya, Label.silver_hair),\n",
    "  (Label.touhou, Label.flandre, Label.blonde_hair),\n",
    "  (Label.touhou, Label.reiuji, Label.black_hair, Label.bird_person),\n",
    "  (Label.touhou, Label.reisen, Label.purple_hair, Label.bunny_ears),\n",
    "  (Label.touhou, Label.tewi, Label.black_hair, Label.bunny_ears),\n",
    "  (Label.touhou, Label.patchouli, Label.purple_hair),\n",
    "  (Label.touhou, Label.aya, Label.black_hair, Label.black_hair),\n",
    "  (Label.hololive, Label.pekora, Label.blue_hair, Label.bunny_ears),\n",
    "  (Label.hololive, Label.kronii, Label.blue_hair),\n",
    "  (Label.hololive, Label.suisei, Label.blue_hair),\n",
    "  (Label.hololive, Label.gura, Label.silver_hair),\n",
    "  (Label.hololive, Label.noel, Label.silver_hair),\n",
    "  (Label.hololive, Label.ame, Label.blonde_hair),\n",
    "  (Label.hololive, Label.subaru, Label.black_hair, Label.bird_person),\n",
    "  (Label.hololive, Label.kiara, Label.black_hair, Label.bird_person),\n",
    ")\n",
    "\n",
    "# def wraparound_iterator(get_iterator: Callable[[], Iterator[T]]) -> Iterator[Tuple[T, int]]:\n",
    "#   for epoch in count(0):\n",
    "#     iterator: Iterator[T] = get_iterator()\n",
    "#     for caption in iterator:\n",
    "#       yield (caption, epoch)\n",
    "\n",
    "def wraparound_iterator(get_iterator: Callable[[], Iterator[T]]) -> Iterator[T]:\n",
    "  while True:\n",
    "    iterator: Iterator[T] = get_iterator()\n",
    "    for caption in iterator:\n",
    "      yield caption\n",
    "\n",
    "def get_caption_iterator() -> Iterator[_Caption]:\n",
    "  return iter(captions)\n",
    "\n",
    "def batches_of(iterator: Iterable[T], batch_size: int) -> Iterator[Tuple[T, ...]]:\n",
    "  while True:\n",
    "    yield tuple(islice(iterator, batch_size))\n",
    "\n",
    "_EpochZipped: TypeAlias = Tuple[int, T]\n",
    "\n",
    "def zip_epoch(iterator: Iterator[T]) -> Iterator[_EpochZipped[T]]:\n",
    "  for epoch in count(0):\n",
    "    for element in iter(iterator):\n",
    "      yield (epoch, element)\n",
    "\n",
    "# def map_epoch_zipped(zipped: Iterable[_EpochZipped[T]], operate: Callable[[Iterable[T]], Iterable[U]]) -> Iterator[_EpochZipped[U]]:\n",
    "#   for (epoch, value) in zipped:\n",
    "#     yield (epoch, operate(value))\n",
    "\n",
    "def map_batched_epoch_zipped(zipped_batches: Iterable[Tuple[_EpochZipped[T], ...]], operate: Callable[[Tuple[T, ...]], U]) -> Iterator[_EpochZipped[U]]:\n",
    "  for zipped_batch in zipped_batches:\n",
    "    (epoch, *_), *_ = zipped_batch\n",
    "    yield (epoch, operate(tuple(map(lambda tup: tup[1], zipped_batch))))\n",
    "\n",
    "batches: Iterable[_EpochZipped[BoolTensor]] = map_batched_epoch_zipped(batches_of(zip_epoch(captions), 2), captions_to_tensor)\n",
    "\n",
    "(batch0, batch1) = tuple(islice(batches, 2))\n",
    "\n",
    "# batches: Iterable[int, BoolTensor] = map(captions_to_tensor, batches_of(get_caption_iterator, 2))\n",
    "\n",
    "class Trainer:\n",
    "  model: Module\n",
    "  epochs: int\n",
    "  batches: Iterable[Tuple[int, BoolTensor]]\n",
    "  def __init__(\n",
    "    self,\n",
    "    model: MultilabelEmbedding,\n",
    "    batches: Iterable[Tuple[int, BoolTensor]],\n",
    "    epochs: int\n",
    "  ) -> None:\n",
    "    self.model = model\n",
    "    self.epochs = epochs\n",
    "    self.batches = batches\n",
    "\n",
    "  def train(self):\n",
    "    epoch = 0\n",
    "    while epoch < self.epochs:\n",
    "      batch_of_captions_tensor: BoolTensor = captions_to_tensor(captions[:2])\n",
    "      self.model.forward(batch_of_captions_tensor)\n",
    "\n",
    "trainer = Trainer(model=model, batches=batches, epochs=1)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78e3a86d817f0305c6e3ca8b7b0d5c058431815e5e5d84824ad7e380695c2da0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
